{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"images.tsv\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[3072].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop(columns=[3072]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_img(x):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(x[i].reshape(32,32,3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.zeros_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = pd.read_csv(\"wb_model.tsv\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return 0.01 * x - 1.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weight.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, y = None):\n",
    "    shifted_logits = x - np.max(x)\n",
    "    Z = np.sum(np.exp(shifted_logits))\n",
    "    log_probs = shifted_logits - np.log(Z)\n",
    "    probs = np.exp(log_probs)\n",
    "    if y != None:\n",
    "        loss = -log_probs[y]\n",
    "        dx = probs.copy()\n",
    "        dx[y] -= 1\n",
    "        return probs, dx\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(preprocess(x[0]) @ w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(a, b):\n",
    "    return mean_squared_error(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_metric = [9999.9, 9999.9, 9999.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(softmax(preprocess(x[0]), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_metric[2] =999.9\n",
    "for i in range(3):\n",
    "    x_orig = np.copy(x[i])\n",
    "    yy = y[i]\n",
    "    x_mod = np.copy(x_orig).astype(float)\n",
    "    lr = 5\n",
    "    while True:\n",
    "        score = softmax(preprocess(x_mod) @ w.T)\n",
    "        grad = np.copy(score)\n",
    "        grad[yy] -= 1\n",
    "        if score[yy] > 0.505:\n",
    "            print(score)\n",
    "            break\n",
    "        dx = grad @ w\n",
    "        print(np.max(dx), np.min(dx))\n",
    "        #break\n",
    "        #llr = -np.sign(dx)\n",
    "        #x_mod += llr\n",
    "        x_mod -= (dx * lr)\n",
    "        x_mod = np.maximum(x_mod, 0)\n",
    "        x_mod = np.minimum(x_mod, 255)\n",
    "        #print(x_mod)\n",
    "        print(score[yy], mse(x_mod, x_orig))\n",
    "    if x_metric[i] > mse(x_mod, x_orig):\n",
    "        x_new[i] = np.copy(x_mod)\n",
    "        x_metric[i] = mse(x_mod, x_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = 1\n",
    "\n",
    "for i in range(3):\n",
    "    x_orig = np.copy(x[i])\n",
    "    yy = y[i]\n",
    "    score = lambda q: softmax(preprocess(q) @ w.T)[yy]\n",
    "    sc = score(x_orig)\n",
    "    j = 0\n",
    "    x_mod = np.array(x_orig)\n",
    "    diff = np.zeros(x_orig.shape[0])\n",
    "    while True:\n",
    "        x_modd = np.array(x_mod)\n",
    "        x_modd[j] = min(255, x_mod[j] + 1)\n",
    "        scor = score(x_modd)\n",
    "        a = mse(x_mod, x_orig)\n",
    "        if scor - sc > coeff*diff.mean():\n",
    "            diff[j] = scor-sc\n",
    "            sc = scor\n",
    "            x_mod[j] += 1\n",
    "        x_modd[j] = max(0, x_mod[j] - 1)\n",
    "        scor = score(x_modd)\n",
    "        if scor - sc > coeff*diff.mean():\n",
    "            diff[j] = scor-sc\n",
    "            sc = scor\n",
    "            x_mod[j] -= 1\n",
    "        \n",
    "        if sc > 0.5:\n",
    "            print(\"YEAH\")\n",
    "            print(mse(x_mod, x_orig))\n",
    "            break\n",
    "        j += 1\n",
    "        if j == x_orig.shape[0]:\n",
    "            #rint(diff.max())\n",
    "            j = 0\n",
    "\n",
    "    if x_metric[i] > mse(x_mod, x_orig):\n",
    "        x_new[i] = x_mod\n",
    "        x_metric[i] = mse(x_mod, x_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappop, heappush\n",
    "\n",
    "hyperpar= 1.7\n",
    "def mymse(x_orig, x_mod, j):\n",
    "    return (x_orig[j] - x_mod[j]) ** 2\n",
    "\n",
    "def add_list(diff, x_mod, j, sc):\n",
    "    x_modd = np.copy(x_mod)\n",
    "    x_modd[j] = min(255, x_mod[j] + 1)\n",
    "    scor = score(x_modd)\n",
    "    if scor - sc > 0:\n",
    "        heappush(diff, (-(scor-sc)**(1/hyperpar)/(mymse(x_modd, x_orig, j)-mymse(x_mod, x_orig, j)), j, 1))\n",
    "        #heappush(diff, ((mymse(x_modd, x_orig, j)-mymse(x_mod, x_orig, j))/(scor-sc)**(1/hyperpar), j, 1))\n",
    "        return\n",
    "    else:\n",
    "        x_modd[j] = max(0, x_mod[j] - 1)\n",
    "        scor = score(x_modd)\n",
    "        if scor - sc > 0:\n",
    "            heappush(diff, (-(scor-sc)**(1/hyperpar)/(mymse(x_modd, x_orig, j)-mymse(x_mod, x_orig, j)), j, -1))\n",
    "            #heappush(diff, ((mymse(x_modd, x_orig, j)-mymse(x_mod, x_orig, j))/(scor-sc)**(1/hyperpar), j, -1))\n",
    "            return\n",
    "\n",
    "for i in range(0, 3):\n",
    "    x_orig = np.copy(x[i])\n",
    "    yy = y[i]\n",
    "    score = lambda q: softmax(preprocess(q) @ w.T)[yy]\n",
    "    sc = score(x_orig)\n",
    "    x_mod = np.array(x_orig)\n",
    "    best_mse = 9999\n",
    "    diff = []\n",
    "    for j in range(x_orig.shape[0]):\n",
    "        add_list(diff, x_mod, j, sc)\n",
    "    while True:\n",
    "        _, j, _sum = heappop(diff)\n",
    "        x_mod[j] += _sum\n",
    "        sc = score(x_mod)\n",
    "        add_list(diff, x_mod, j, sc)\n",
    "        if sc > 0.5:\n",
    "            mmssee = mse(x_mod, x_orig)\n",
    "            if best_mse > mmssee:\n",
    "                print(\"BEST\")\n",
    "                best_mse = mmssee\n",
    "                best_arr = np.copy(x_mod)\n",
    "        if sc > 0.6:\n",
    "            print(\"0.6!\")\n",
    "            break\n",
    "    if x_metric[i] > mse(x_mod, x_orig):\n",
    "        x_new[i] = x_mod\n",
    "        x_metric[i] = mse(x_mod, x_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_metric, x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_img(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_img(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mse(x_new, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(x_new[0] - x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(x_new[i])\n",
    "    print(softmax(preprocess(x_new[i]) @ w.T)[y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"task_p_out.txt\", x_new, fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpreprocess(x):\n",
    "    return torch.Tensor(0.01 * x - 1.28)\n",
    "\n",
    "def tdeprocess(x):\n",
    "    return (100 * x + 128).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(32*32*3, 10, bias=False))\n",
    "for param in model.parameters():\n",
    "    param = torch.tensor(w)\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fooling_image(X, target_y, model):\n",
    "    \"\"\"\n",
    "    Generate a fooling image that is close to X, but that the model classifies\n",
    "    as target_y.\n",
    "\n",
    "    Inputs:\n",
    "    - X: Input image; Tensor of shape (1, 3, 224, 224)\n",
    "    - target_y: An integer in the range [0, 1000)\n",
    "    - model: A pretrained CNN\n",
    "\n",
    "    Returns:\n",
    "    - X_fooling: An image that is close to X, but that is classifed as target_y\n",
    "    by the model.\n",
    "    \"\"\"\n",
    "    # Initialize our fooling image to the input image, and make it require gradient\n",
    "    X_fooling = X.clone()\n",
    "    X_fooling = X_fooling.requires_grad_()\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    ##############################################################################\n",
    "    # TODO: Generate a fooling image X_fooling that the model will classify as   #\n",
    "    # the class target_y. You should perform gradient ascent on the score of the #\n",
    "    # target class, stopping when the model is fooled.                           #\n",
    "    # When computing an update step, first normalize the gradient:               #\n",
    "    #   dX = learning_rate * g / ||g||_2                                         #\n",
    "    #                                                                            #\n",
    "    # You should write a training loop.                                          #\n",
    "    #                                                                            #\n",
    "    # HINT: For most examples, you should be able to generate a fooling image    #\n",
    "    # in fewer than 100 iterations of gradient ascent.                           #\n",
    "    # You can print your progress over iterations to check your algorithm.       #\n",
    "    ##############################################################################\n",
    "    \n",
    "    for _ in range(10000):\n",
    "        scores = model(X_fooling)\n",
    "        print(softmax(X_fooling.clone().data.numpy() @ w.T)[target_y])\n",
    "        if softmax(X_fooling.data.numpy() @ w.T)[target_y] > 0.5:\n",
    "            break\n",
    "        loss = scores[target_y]\n",
    "        loss.backward()\n",
    "        dx = learning_rate * X_fooling.grad #/ X_fooling.grad.norm()\n",
    "        with torch.no_grad():\n",
    "            X_fooling += dx\n",
    "            X_fooling.grad.zero_()\n",
    "    ##############################################################################\n",
    "    #                             END OF YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    return X_fooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "target_y = 3\n",
    "ndx = x[0]\n",
    "\n",
    "X_tensor = tpreprocess(ndx)\n",
    "X_fooling = make_fooling_image(X_tensor, target_y, model)\n",
    "scores = model(X_fooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(x):\n",
    "    return (x + 1.28) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fooling_np = tdeprocess(X_fooling.clone())\n",
    "X_fooling_np = np.asarray(X_fooling_np.data).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fooling_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_fooling_np.reshape(32,32,3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(X_fooling_np,x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(preprocess(X_fooling_np) @ w.T)[target_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
